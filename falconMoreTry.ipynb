{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213d1e1c-6f20-489c-938e-a223dbf51aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.150 requires botocore==1.29.150, but you have botocore 1.31.1 which is incompatible.\n",
      "awscli 1.27.150 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker boto3 --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bced988e-12ad-4d24-9016-bb8cf951bf75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import jinja2\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sagemaker.utils import name_from_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9526a0-d4ef-4dc8-99d5-ae4d28731935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "model_bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "s3_code_prefix_deepspeed = \"hf-large-model-djl-/code_falcon7b/deepspeed\"  # folder within bucket where code artifact will go\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "jinja_env = jinja2.Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f828a66b-7cc8-4fb0-9af7-f4a5e39466ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p code_falcon7b_deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805e0798-c831-4173-9602-8a737e9dda17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model will be downloaded from ---- > s3://sagemaker-us-east-1-303179550733/huggingface-peft-2023-07-06-08-45-07-2023-07-06-08-45-14-350/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# define a variable to contain the s3url of the location that has the model\n",
    "pretrained_model_location = f\"s3://sagemaker-us-east-1-303179550733/huggingface-peft-2023-07-06-08-45-07-2023-07-06-08-45-14-350/output/model.tar.gz\"\n",
    "print(f\"Pretrained model will be downloaded from ---- > {pretrained_model_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204038e8-a164-4797-8703-3cd3e1d815a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code_falcon7b_deepspeed/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code_falcon7b_deepspeed/serving.properties\n",
    "engine=DeepSpeed\n",
    "option.model_id=tiiuae/falcon-7b\n",
    "option.tensor_parallel_degree=1\n",
    "#option.s3url = {{s3url}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95555ca-3921-42e2-ab26-a047ee1e756e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code_falcon7b_deepspeed/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code_falcon7b_deepspeed/requirements.txt\n",
    "einops\n",
    "torch==2.0.1\n",
    "git+https://github.com/lanking520/DeepSpeed.git@falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef1df57-e0b4-423b-83c8-8c040283fc54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code_falcon7b_deepspeed/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code_falcon7b_deepspeed/model.py\n",
    "from djl_python import Input, Output\n",
    "import os\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import Any, Dict, Tuple\n",
    "import deepspeed\n",
    "import warnings\n",
    "\n",
    "predictor = None\n",
    "\n",
    "\n",
    "def get_model(properties):\n",
    "    model_name = properties[\"model_id\"]\n",
    "    local_rank = int(os.getenv(\"LOCAL_RANK\", \"0\"))\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, low_cpu_mem_usage=True, trust_remote_code=True, torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    model = deepspeed.init_inference(model, mp_size=properties[\"tensor_parallel_degree\"])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generator = pipeline(\n",
    "        task=\"text-generation\", model=model, tokenizer=tokenizer, device=local_rank\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "\n",
    "def handle(inputs: Input) -> None:\n",
    "    global predictor\n",
    "    if not predictor:\n",
    "        predictor = get_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    text = data[\"text\"]\n",
    "    text_length = data[\"text_length\"]\n",
    "    result = predictor(text, do_sample=True, min_length=text_length, max_length=text_length)\n",
    "    return Output().add(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2c8726-fa6d-481f-aead-94ee9b4b7af5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./model.py\n",
      "./serving.properties\n",
      "./requirements.txt\n",
      "S3 Code or Model tar for deepspeed uploaded to --- > s3://sagemaker-us-east-1-303179550733/hf-large-model-djl-/code_falcon7b/deepspeed/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!rm -f model.tar.gz\n",
    "!rm -rf code_falcon7b_deepspeed/.ipynb_checkpoints\n",
    "!tar czvf model.tar.gz -C code_falcon7b_deepspeed .\n",
    "s3_code_artifact_deepspeed = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix_deepspeed)\n",
    "print(f\"S3 Code or Model tar for deepspeed uploaded to --- > {s3_code_artifact_deepspeed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a72c8a8-8f55-4479-ba63-cdef396c09e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\n"
     ]
    }
   ],
   "source": [
    "# inference_image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/djl-ds:latest\"\n",
    "inference_image_uri = (\n",
    "    f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\"\n",
    ")\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b28323b-e780-464a-8efc-8ccc710e003f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falcon7b-model-ds-2023-07-08-11-03-30-763\n"
     ]
    }
   ],
   "source": [
    "model_name_ds = name_from_base(f\"falcon7b-model-ds\")\n",
    "print(model_name_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bef64b8-cc40-4471-a4a6-f98a7a2d5426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Model: arn:aws:sagemaker:us-east-1:303179550733:model/falcon7b-model-ds-2023-07-08-11-03-30-763\n"
     ]
    }
   ],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name_ds,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\"Image\": inference_image_uri, \"ModelDataUrl\": s3_code_artifact_deepspeed},\n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48b55f8c-1076-4fda-aef2-211b315876f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building EndpointConfig and Endpoint for: falcon7b-model-ds-2023-07-08-11-03-30-763\n"
     ]
    }
   ],
   "source": [
    "model_name = model_name_ds\n",
    "print(f\"Building EndpointConfig and Endpoint for: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17eee3d4-56bc-4304-ab61-569f513f36aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:303179550733:endpoint-config/falcon7b-model-ds-2023-07-08-11-03-30-763-config',\n",
       " 'ResponseMetadata': {'RequestId': '51da8451-7200-407e-a74e-a0d5cae30175',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '51da8451-7200-407e-a74e-a0d5cae30175',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '129',\n",
       "   'date': 'Sat, 08 Jul 2023 11:03:56 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g5.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelDataDownloadTimeoutInSeconds\": 3600,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600,\n",
    "            # \"VolumeSizeInGB\": 512\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f91f31d1-1ee9-4e78-aaa6-1341c14e21b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Endpoint: arn:aws:sagemaker:us-east-1:303179550733:endpoint/falcon7b-model-ds-2023-07-08-11-03-30-763-endpoint\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9690f1b3-1c89-43df-b33c-8b24df3e5dea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:303179550733:endpoint/falcon7b-model-ds-2023-07-08-11-03-30-763-endpoint\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6699d64-206c-434c-97bb-8428a535fd84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 785 µs, total: 20.7 ms\n",
      "Wall time: 9.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"generated_text\":\"What is the purpose of life?\\\\nIn the next few posts we are going to deal with the question: “what is the purpose of life?” I believe as we search for the answer to this question we are looking for an eternal, eternal purpose that will be an expression of God’s glory, that is, we want God’s purpose to be our purpose. But, what is an eternal purpose? Is this a contradiction?\\\\nThe word eternal in English means, “without beginning or ending in time.” So we see that in the phrase eternal purpose there is no beginning or ending. So if we want to go to the beginning we want to know what God was doing before there was anything in the universe. “What\"\\n  }\\n]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response_model = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps({\"text\": \"What is the purpose of life?\", \"text_length\": 150}),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "\n",
    "response_model[\"Body\"].read().decode(\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c1a2805-2ae0-49d2-bde9-0e2004056cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'falcon7b-model-ds-2023-07-08-11-03-30-763-endpoint'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
